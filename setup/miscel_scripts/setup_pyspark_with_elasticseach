1. get jar file from maven(we got 2.2.0)
http://search.maven.org/remotecontent?filepath=org/elasticsearch/elasticsearch-hadoop/2.2.0/elasticsearch-hadoop-2.2.0.jar
2. create "jars" directory under /usr/local/spark 

3. COPY jar from from step 1 to jars directory
4. start pyspark like this (no ipython)
./bin/pyspark --master local[4] --jars jars/elasticsearch-hadoop-2.2.0.jar

5. USING IPYTHON
IPYTHON_OPTS="notebook" $SPARK_HOME/bin/pyspark --master local[4] --jars jars/elasticsearch-hadoop-2.2.0.jar
#above will start ipython notebook
spark context is available as variable "sc"
IPYTHON_OPTS="notebook --certfile=~/cert/mycert.pem --keyfile ~/cert/mykey.key" $SPARK_HOME/bin/pyspark --master spark://spark1:7077 --jars jars/elasticsearch-hadoop-2.2.0.jar

