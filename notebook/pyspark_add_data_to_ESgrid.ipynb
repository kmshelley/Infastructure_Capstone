{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "# This notebook server was started with command below, in which case \"sc\" is a spark context \n",
    "\n",
    "*IPYTHON_OPTS=\"notebook --certfile=~/cert/mycert.pem --keyfile ~/cert/mykey.key\" $SPARK_HOME/bin/pyspark --master spark://spark1:7077 --jars $SPARK_HOME/jars/elasticsearch-hadoop-2.2.0.jar*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.53.138.84\n"
     ]
    }
   ],
   "source": [
    "#lat/lon grid class\n",
    "import sys\n",
    "sys.path.append('../Infrastructure_Capstone')\n",
    "import os\n",
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "from pyproj import Proj\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch.client import indices\n",
    "#from dataStorage import upload_to_Elasticsearch\n",
    "import ConfigParser\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "\n",
    "#read in the config file\n",
    "#os.chdir('~/Infrastructure_Capstone')\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.read('../Infrastructure_Capstone/config/capstone_config.ini')\n",
    "\n",
    "ES_url = config.get('ElasticSearch','host')\n",
    "ES_password = config.get('ElasticSearch','password')\n",
    "ES_username= config.get('ElasticSearch','username')\n",
    "\n",
    "print ES_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "central_park_wban = \"94728\"\n",
    "\n",
    "#functions to add weather data to grid based on closest weather station. If closest station does not have a reading \n",
    "#for that time period, use Central Park station\n",
    "def get_weather_reading(wban,time):\n",
    "    #searches ES for weather readings from station id wban, closest to the given time\n",
    "    #find weather observations for the nearest weather station and time\n",
    "    es_url = 'http://%s:%s@%s:9200' % (ES_username,ES_password,ES_url)\n",
    "    es = Elasticsearch(es_url)\n",
    "    \n",
    "\n",
    "    query = '''{\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\" : { \"term\": { \"weather_WBAN\" : \"%s\"} },\n",
    "                        \"must\" : {\n",
    "                            \"range\" : {\n",
    "                                \"weather_DateTime\" : {\n",
    "                                        \"gte\": \"%s\",\n",
    "                                        \"lt\": \"%s\",\n",
    "                                        \"format\": \"MM/dd/yyyy HH:mm\"\n",
    "                                }\n",
    "                            }\n",
    "                        } \n",
    "                    }\n",
    "                }\n",
    "            }''' % (wban,dt.datetime.strftime(time + dt.timedelta(seconds=-3600),'%m/%d/%Y %H:%M'),dt.datetime.strftime(time + dt.timedelta(seconds=3600),'%m/%d/%Y %H:%M'))\n",
    "\n",
    "    \n",
    "    observations = list(helpers.scan(es,query=query,index='weather',doc_type='hourly_obs')) #get the first observation returned\n",
    "    if len(observations) > 0:\n",
    "        min_diff = float('inf')\n",
    "        best_obs = None\n",
    "        #iterate through the returned observations, add the closest observation in time\n",
    "        for obs in observations:\n",
    "            obs_time = parse(obs['_source']['weather_DateTime']).replace(tzinfo=None)\n",
    "            if abs((obs_time - time).total_seconds()) < min_diff:\n",
    "                best_obs = obs['_source']\n",
    "                min_diff = abs((obs_time - time).total_seconds())\n",
    "        return best_obs\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_weather(row):\n",
    "    key,val = row\n",
    "\n",
    "    es_url = 'http://%s:%s@%s:9200' % (ES_username,ES_password,ES_url)\n",
    "    es = Elasticsearch(es_url)\n",
    "    \n",
    "    proj = Proj(init='epsg:2263')\n",
    "    updates = []\n",
    "    idx=0\n",
    "    update = deepcopy(val)\n",
    "    date_hour = parse(val['grid_fullDate']).replace(tzinfo=None)\n",
    "    \n",
    "    query = '{ \\\n",
    "              \"query\": { \\\n",
    "                \"bool\": { \\\n",
    "                  \"must\": { \\\n",
    "                    \"wildcard\": { \"ZCTA5CE10\" : \"%s*\" } \\\n",
    "                  } \\\n",
    "                } \\\n",
    "              } \\\n",
    "            }' % val['grid_zipcode']\n",
    "\n",
    "    #find the largest zip code area to represent the grid area\n",
    "    max_area = 0\n",
    "    wban = None\n",
    "    #query the zip codes, finding all zip shapes that contain the current colision\n",
    "    for shape in helpers.scan(es,query=query,index='nyc_zip_codes',doc_type='zip_codes'):\n",
    "        coords = [proj(lng,lat) for lng,lat in shape['_source']['coords']['coordinates'][0]]\n",
    "        poly = Polygon(coords)\n",
    "        if poly.area > max_area:\n",
    "            #get the largest zip code by geographic area\n",
    "            max_area = poly.area\n",
    "            wban = shape['_source']['closest_weather_stations']\n",
    "\n",
    "    #find weather observations for the nearest weather station and time\n",
    "    observation = get_weather_reading(wban,date_hour)\n",
    "    if observation:\n",
    "        #numerical fields, change 99999 values to NA\n",
    "        update['weather_WetBulbFarenheit'] = observation['weather_WetBulbFarenheit'] \n",
    "        update['weather_WindSpeed'] = observation['weather_WindSpeed']\n",
    "        update['weather_Visibility'] = observation['weather_Visibility']\n",
    "        update['weather_HourlyPrecip'] = observation['weather_HourlyPrecip']           \n",
    "\n",
    "        #string fields\n",
    "\n",
    "        update['weather_SkyCondition'] = observation['weather_SkyCondition'] #Adjust this for just condition?\n",
    "        update['weather_WeatherType'] = observation['weather_WeatherType']\n",
    "\n",
    "        weather_list = observation['weather_WeatherType'].split(' ') #space delimited list\n",
    "        #Types of rain\n",
    "        update['weather_Rain'] = 0 #no rain\n",
    "        if '-RA' in weather_list or '-DZ' in weather_list or '-SH' in weather_list or '-FZRA' in weather_list: \n",
    "            update['weather_Rain'] = 1 #light rain\n",
    "        if 'RA' in weather_list or 'DZ' in weather_list or 'SH' in weather_list or 'FZRA' in weather_list: \n",
    "            update['weather_Rain'] = 2 #moderate rain\n",
    "        if '+RA' in weather_list or '+DZ' in weather_list or '+SH' in weather_list or '+FZRA' in weather_list: \n",
    "            update['weather_Rain'] = 3 #heavy rain\n",
    "\n",
    "\n",
    "        #Types of snow/hail/ice\n",
    "        update['weather_SnowHailIce'] = 0 #none\n",
    "        if '-SN' in weather_list or '+SG' in weather_list or '-GS' in weather_list or '-GR' in weather_list or '-PL' in weather_list or '-IC' in weather_list:\n",
    "            update['weather_SnowHailIce'] = 1 #light\n",
    "        if 'SN' in weather_list or '+SG' in weather_list or 'GS' in weather_list or 'GR' in weather_list or 'PL' in weather_list or 'IC' in weather_list:\n",
    "            update['weather_SnowHailIce'] = 2 #moderate \n",
    "        if '+SN' in weather_list or '+SG' in weather_list or '+GS' in weather_list or '+GR' in weather_list or '+PL' in weather_list or '+IC' in weather_list:\n",
    "            update['weather_SnowHailIce'] = 3 #heavy             \n",
    "\n",
    "\n",
    "        #Types of fog/mist\n",
    "        update['weather_Fog'] = 0 #none\n",
    "        if '-FG' in weather_list or '-BR' in weather_list or '-HZ' in weather_list:\n",
    "            update['weather_Fog'] = 1 #light\n",
    "        if 'FG' in weather_list or 'BR' in weather_list or 'HZ' in weather_list:\n",
    "            update['weather_Fog'] = 2 #moderate \n",
    "        if '+FG' in weather_list or '+BR' in weather_list or '+HZ' in weather_list or 'FG+' in weather_list:\n",
    "            update['weather_Fog'] = 3 #heavy \n",
    "\n",
    "    else:\n",
    "        #find weather observations for central park station and time\n",
    "        observation = get_weather_reading(central_park_wban,date_hour)\n",
    "        if observation:\n",
    "            #numerical fields, change 99999 values to NA\n",
    "            update['weather_WetBulbFarenheit'] = observation['weather_WetBulbFarenheit']\n",
    "            update['weather_WindSpeed'] = observation['weather_WindSpeed']\n",
    "            update['weather_Visibility'] = observation['weather_Visibility']\n",
    "            update['weather_HourlyPrecip'] = observation['weather_HourlyPrecip']            \n",
    "\n",
    "            #string fields\n",
    "\n",
    "            update['weather_SkyCondition'] = observation['weather_SkyCondition'] #Adjust this for just condition?\n",
    "            update['weather_WeatherType'] = observation['weather_WeatherType']\n",
    "\n",
    "            weather_list = observation['weather_WeatherType'].split(' ') #space delimited list\n",
    "            #Types of rain\n",
    "            update['weather_Rain'] = 0 #no rain\n",
    "            if '-RA' in weather_list or '-DZ' in weather_list or '-SH' in weather_list or '-FZRA' in weather_list: \n",
    "                update['weather_Rain'] = 1 #light rain\n",
    "            if 'RA' in weather_list or 'DZ' in weather_list or 'SH' in weather_list or 'FZRA' in weather_list: \n",
    "                update['weather_Rain'] = 2 #moderate rain\n",
    "            if '+RA' in weather_list or '+DZ' in weather_list or '+SH' in weather_list or '+FZRA' in weather_list: \n",
    "                update['weather_Rain'] = 3 #heavy rain\n",
    "            \n",
    "\n",
    "            #Types of snow/hail/ice\n",
    "            update['weather_SnowHailIce'] = 0 #none\n",
    "            if '-SN' in weather_list or '+SG' in weather_list or '-GS' in weather_list or '-GR' in weather_list or '-PL' in weather_list or '-IC' in weather_list:\n",
    "                update['weather_SnowHailIce'] = 1 #light\n",
    "            if 'SN' in weather_list or '+SG' in weather_list or 'GS' in weather_list or 'GR' in weather_list or 'PL' in weather_list or 'IC' in weather_list:\n",
    "                update['weather_SnowHailIce'] = 2 #moderate \n",
    "            if '+SN' in weather_list or '+SG' in weather_list or '+GS' in weather_list or '+GR' in weather_list or '+PL' in weather_list or '+IC' in weather_list:\n",
    "                update['weather_SnowHailIce'] = 3 #heavy             \n",
    "            \n",
    "\n",
    "            #Types of fog/mist\n",
    "            update['weather_Fog'] = 0 #none\n",
    "            if '-FG' in weather_list or '-BR' in weather_list or '-HZ' in weather_list:\n",
    "                update['weather_Fog'] = 1 #light\n",
    "            if 'FG' in weather_list or 'BR' in weather_list or 'HZ' in weather_list:\n",
    "                update['weather_Fog'] = 2 #moderate \n",
    "            if '+FG' in weather_list or '+BR' in weather_list or '+HZ' in weather_list or 'FG+' in weather_list:\n",
    "                update['weather_Fog'] = 3 #heavy \n",
    "            \n",
    "            \n",
    "            \n",
    "        #otherwise, no weather data, fill values with NA        \n",
    "        else:\n",
    "            #numerical fields, change 99999 values to NA\n",
    "            update['weather_WetBulbFarenheit'] = 99999\n",
    "            update['weather_WindSpeed'] = 99999\n",
    "            update['weather_Visibility'] = 99999\n",
    "            update['weather_HourlyPrecip'] = 99999            \n",
    "\n",
    "            #string fields\n",
    "            update['weather_SkyCondition'] = 'NA'   \n",
    "            update['weather_WeatherType'] = 'NA'\n",
    "            update['weather_Rain'] = 99999\n",
    "            update['weather_SnowHailIce'] = 99999\n",
    "            update['weather_Fog'] = 99999\n",
    "\n",
    "    return (key,update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7faf140beb50>\n"
     ]
    }
   ],
   "source": [
    "#print sc to see what it is\n",
    "print sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_write_conf = {\n",
    "        \"es.nodes\" : ES_url,\n",
    "        \"es.port\" : \"9200\",\n",
    "        \"es.net.http.auth.user\" : ES_username, \n",
    "        \"es.net.http.auth.pass\" : ES_password,\n",
    "        \"es.resource\" : \"dataframe_plus_weather/rows\",\n",
    "        \"es.mapping.id\" : \"grid_id\"\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'2013-02-06T13:00:00_10306',\n",
       " {u'grid_day': 6,\n",
       "  u'grid_dayOfWeek': 3,\n",
       "  u'grid_fullDate': u'2013-02-06T12:00:00-06:00',\n",
       "  u'grid_hourOfDay': 13,\n",
       "  u'grid_id': u'2013-02-06T13:00:00_10306',\n",
       "  u'grid_isAccident': 0,\n",
       "  u'grid_month': 2,\n",
       "  u'grid_zipcode': 10306})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rdd = sc.newAPIHadoopRDD(\n",
    "    inputFormatClass=\"org.elasticsearch.hadoop.mr.EsInputFormat\",\n",
    "    keyClass=\"org.apache.hadoop.io.NullWritable\", \n",
    "    valueClass=\"org.elasticsearch.hadoop.mr.LinkedMapWritable\", \n",
    "    conf={ \"es.resource\" : \"dataframe/rows\", \"es.nodes\" : ES_url, \n",
    "          \"es.net.http.auth.user\" : ES_username, \n",
    "          \"es.net.http.auth.pass\" : ES_password })\n",
    "\n",
    "grid_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_rdd = grid_rdd.map(add_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_rdd.saveAsNewAPIHadoopFile(\n",
    "            path='-', \n",
    "            outputFormatClass=\"org.elasticsearch.hadoop.mr.EsOutputFormat\",\n",
    "            keyClass=\"org.apache.hadoop.io.NullWritable\", \n",
    "            valueClass=\"org.elasticsearch.hadoop.mr.LinkedMapWritable\", \n",
    "            conf=es_write_conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
